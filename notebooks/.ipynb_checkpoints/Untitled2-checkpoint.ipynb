{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9598e605-b9a5-49f6-98c9-8cd1fce6b915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym[box2d] in /usr/local/lib/python3.7/site-packages (0.21.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/site-packages (from gym[box2d]) (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/site-packages (from gym[box2d]) (1.21.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.1 in /usr/local/lib/python3.7/site-packages (from gym[box2d]) (4.8.1)\n",
      "Requirement already satisfied: pyglet>=1.4.0 in /usr/local/lib/python3.7/site-packages (from gym[box2d]) (1.5.21)\n",
      "Requirement already satisfied: box2d-py==2.3.5 in /usr/local/lib/python3.7/site-packages (from gym[box2d]) (2.3.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata>=4.8.1->gym[box2d]) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/site-packages (from importlib-metadata>=4.8.1->gym[box2d]) (3.10.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "!pip install gym[box2d]\n",
    "import gym\n",
    "from cogment_verse_torch_agents.muzero.agent import reward_transform, reward_transform_inverse, DynamicsAdapter\n",
    "from cogment_verse_torch_agents.muzero.networks import resnet, Distributional\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be1a84bf-80e5-40ca-80ae-ce2f6930aeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dim = 8\n",
    "act_dim = 4\n",
    "hidden_dim = 32\n",
    "hidden_layers = 2\n",
    "rbins = 32\n",
    "rmin = -100\n",
    "rmax = 100\n",
    "\n",
    "reward_distribution = Distributional(\n",
    "    rmin,\n",
    "    rmax,\n",
    "    hidden_dim,\n",
    "    rbins,\n",
    "    reward_transform,\n",
    "    reward_transform_inverse,\n",
    ")\n",
    "\n",
    "dynamics = DynamicsAdapter(\n",
    "    resnet(\n",
    "        obs_dim + act_dim,\n",
    "        hidden_dim,\n",
    "        hidden_dim,\n",
    "        hidden_layers - 1,\n",
    "        final_act=torch.nn.LeakyReLU(),\n",
    "    ),\n",
    "    act_dim,\n",
    "    hidden_dim,\n",
    "    obs_dim,\n",
    "    reward_dist=reward_distribution,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf26671f-1cd1-4fbd-9f36-f4f236777f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = []\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "140d2a0c-cd8b-423f-a0ab-bfb699d3e74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss_r': tensor(3.4937, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7542, grad_fn=<MeanBackward0>), 'loss': tensor(4.2479, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5100, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7821, grad_fn=<MeanBackward0>), 'loss': tensor(4.2921, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4573, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7632, grad_fn=<MeanBackward0>), 'loss': tensor(4.2204, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5797, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7996, grad_fn=<MeanBackward0>), 'loss': tensor(4.3793, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4521, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8148, grad_fn=<MeanBackward0>), 'loss': tensor(4.2670, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.3879, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7485, grad_fn=<MeanBackward0>), 'loss': tensor(4.1364, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4879, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7793, grad_fn=<MeanBackward0>), 'loss': tensor(4.2672, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4113, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7925, grad_fn=<MeanBackward0>), 'loss': tensor(4.2038, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.3944, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7245, grad_fn=<MeanBackward0>), 'loss': tensor(4.1189, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4389, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8052, grad_fn=<MeanBackward0>), 'loss': tensor(4.2441, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5821, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7810, grad_fn=<MeanBackward0>), 'loss': tensor(4.3631, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5536, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8027, grad_fn=<MeanBackward0>), 'loss': tensor(4.3564, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.3748, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7498, grad_fn=<MeanBackward0>), 'loss': tensor(4.1247, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5057, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7822, grad_fn=<MeanBackward0>), 'loss': tensor(4.2878, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4913, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8085, grad_fn=<MeanBackward0>), 'loss': tensor(4.2998, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4711, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7527, grad_fn=<MeanBackward0>), 'loss': tensor(4.2238, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4934, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7735, grad_fn=<MeanBackward0>), 'loss': tensor(4.2669, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4260, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7444, grad_fn=<MeanBackward0>), 'loss': tensor(4.1704, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4867, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7681, grad_fn=<MeanBackward0>), 'loss': tensor(4.2549, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.3853, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8109, grad_fn=<MeanBackward0>), 'loss': tensor(4.1962, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5134, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7577, grad_fn=<MeanBackward0>), 'loss': tensor(4.2710, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4868, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8234, grad_fn=<MeanBackward0>), 'loss': tensor(4.3102, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4268, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7869, grad_fn=<MeanBackward0>), 'loss': tensor(4.2137, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5176, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7931, grad_fn=<MeanBackward0>), 'loss': tensor(4.3106, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5989, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8072, grad_fn=<MeanBackward0>), 'loss': tensor(4.4061, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5189, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7875, grad_fn=<MeanBackward0>), 'loss': tensor(4.3065, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5112, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8331, grad_fn=<MeanBackward0>), 'loss': tensor(4.3443, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5455, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7640, grad_fn=<MeanBackward0>), 'loss': tensor(4.3095, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.3883, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7893, grad_fn=<MeanBackward0>), 'loss': tensor(4.1776, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5084, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7589, grad_fn=<MeanBackward0>), 'loss': tensor(4.2673, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.6093, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8543, grad_fn=<MeanBackward0>), 'loss': tensor(4.4636, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4438, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7640, grad_fn=<MeanBackward0>), 'loss': tensor(4.2078, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4270, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8218, grad_fn=<MeanBackward0>), 'loss': tensor(4.2488, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4754, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8029, grad_fn=<MeanBackward0>), 'loss': tensor(4.2783, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5955, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7674, grad_fn=<MeanBackward0>), 'loss': tensor(4.3629, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.3569, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7467, grad_fn=<MeanBackward0>), 'loss': tensor(4.1037, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4143, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8010, grad_fn=<MeanBackward0>), 'loss': tensor(4.2153, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4314, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8092, grad_fn=<MeanBackward0>), 'loss': tensor(4.2407, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.6080, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8031, grad_fn=<MeanBackward0>), 'loss': tensor(4.4112, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4162, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8100, grad_fn=<MeanBackward0>), 'loss': tensor(4.2262, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4797, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8290, grad_fn=<MeanBackward0>), 'loss': tensor(4.3087, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4722, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8162, grad_fn=<MeanBackward0>), 'loss': tensor(4.2884, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4377, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7523, grad_fn=<MeanBackward0>), 'loss': tensor(4.1900, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4889, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8397, grad_fn=<MeanBackward0>), 'loss': tensor(4.3286, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4766, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8021, grad_fn=<MeanBackward0>), 'loss': tensor(4.2787, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.3919, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7884, grad_fn=<MeanBackward0>), 'loss': tensor(4.1804, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5589, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8274, grad_fn=<MeanBackward0>), 'loss': tensor(4.3863, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.3759, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7923, grad_fn=<MeanBackward0>), 'loss': tensor(4.1682, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4963, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7751, grad_fn=<MeanBackward0>), 'loss': tensor(4.2714, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4841, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8153, grad_fn=<MeanBackward0>), 'loss': tensor(4.2994, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4860, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8072, grad_fn=<MeanBackward0>), 'loss': tensor(4.2931, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4074, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7752, grad_fn=<MeanBackward0>), 'loss': tensor(4.1826, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5754, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8272, grad_fn=<MeanBackward0>), 'loss': tensor(4.4026, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5275, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7478, grad_fn=<MeanBackward0>), 'loss': tensor(4.2754, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4441, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7771, grad_fn=<MeanBackward0>), 'loss': tensor(4.2212, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4674, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8354, grad_fn=<MeanBackward0>), 'loss': tensor(4.3028, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5271, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7835, grad_fn=<MeanBackward0>), 'loss': tensor(4.3106, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.6171, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8605, grad_fn=<MeanBackward0>), 'loss': tensor(4.4776, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4570, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8105, grad_fn=<MeanBackward0>), 'loss': tensor(4.2675, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4547, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8150, grad_fn=<MeanBackward0>), 'loss': tensor(4.2697, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4657, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8525, grad_fn=<MeanBackward0>), 'loss': tensor(4.3182, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5026, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7783, grad_fn=<MeanBackward0>), 'loss': tensor(4.2808, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5656, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7811, grad_fn=<MeanBackward0>), 'loss': tensor(4.3467, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.6342, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8519, grad_fn=<MeanBackward0>), 'loss': tensor(4.4861, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4380, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7915, grad_fn=<MeanBackward0>), 'loss': tensor(4.2295, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.6490, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8045, grad_fn=<MeanBackward0>), 'loss': tensor(4.4535, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.6007, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8613, grad_fn=<MeanBackward0>), 'loss': tensor(4.4621, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4345, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8303, grad_fn=<MeanBackward0>), 'loss': tensor(4.2647, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5655, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8100, grad_fn=<MeanBackward0>), 'loss': tensor(4.3754, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5133, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8127, grad_fn=<MeanBackward0>), 'loss': tensor(4.3260, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4424, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8067, grad_fn=<MeanBackward0>), 'loss': tensor(4.2491, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.6067, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8063, grad_fn=<MeanBackward0>), 'loss': tensor(4.4130, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5148, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7909, grad_fn=<MeanBackward0>), 'loss': tensor(4.3056, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5300, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7908, grad_fn=<MeanBackward0>), 'loss': tensor(4.3208, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5052, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8262, grad_fn=<MeanBackward0>), 'loss': tensor(4.3314, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5010, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8148, grad_fn=<MeanBackward0>), 'loss': tensor(4.3158, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5464, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8219, grad_fn=<MeanBackward0>), 'loss': tensor(4.3683, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5080, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8270, grad_fn=<MeanBackward0>), 'loss': tensor(4.3350, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5296, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8868, grad_fn=<MeanBackward0>), 'loss': tensor(4.4164, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4506, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7662, grad_fn=<MeanBackward0>), 'loss': tensor(4.2169, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5765, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8109, grad_fn=<MeanBackward0>), 'loss': tensor(4.3874, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4415, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7883, grad_fn=<MeanBackward0>), 'loss': tensor(4.2298, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5828, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7832, grad_fn=<MeanBackward0>), 'loss': tensor(4.3660, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4435, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8074, grad_fn=<MeanBackward0>), 'loss': tensor(4.2509, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4941, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7655, grad_fn=<MeanBackward0>), 'loss': tensor(4.2596, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5532, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8062, grad_fn=<MeanBackward0>), 'loss': tensor(4.3594, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5804, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8248, grad_fn=<MeanBackward0>), 'loss': tensor(4.4053, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5225, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8063, grad_fn=<MeanBackward0>), 'loss': tensor(4.3289, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4493, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8129, grad_fn=<MeanBackward0>), 'loss': tensor(4.2622, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5157, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.9076, grad_fn=<MeanBackward0>), 'loss': tensor(4.4233, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.6014, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7787, grad_fn=<MeanBackward0>), 'loss': tensor(4.3801, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5082, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7822, grad_fn=<MeanBackward0>), 'loss': tensor(4.2904, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5218, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8146, grad_fn=<MeanBackward0>), 'loss': tensor(4.3364, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.6505, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8809, grad_fn=<MeanBackward0>), 'loss': tensor(4.5314, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5637, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7931, grad_fn=<MeanBackward0>), 'loss': tensor(4.3568, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5374, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7941, grad_fn=<MeanBackward0>), 'loss': tensor(4.3315, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.5321, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8162, grad_fn=<MeanBackward0>), 'loss': tensor(4.3483, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4625, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8075, grad_fn=<MeanBackward0>), 'loss': tensor(4.2700, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.4879, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.7506, grad_fn=<MeanBackward0>), 'loss': tensor(4.2385, grad_fn=<AddBackward0>)}\n",
      "{'loss_r': tensor(3.7465, grad_fn=<MeanBackward0>), 'loss_s': tensor(0.8616, grad_fn=<MeanBackward0>), 'loss': tensor(4.6081, grad_fn=<AddBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"LunarLander-v2\")\n",
    "state = env.reset()\n",
    "\n",
    "def cross_entropy(pred, target):\n",
    "    return torch.mean(torch.sum(-target * torch.log(pred), dim=1))\n",
    "\n",
    "def train_step(dynamics, batch):\n",
    "    state, action, reward, new_state = batch\n",
    "    pred_next_state, pred_reward_probs, pred_reward = dynamics(state, action.view(-1))\n",
    "    target_reward_probs = reward_distribution.compute_target(reward)\n",
    "    loss_r = cross_entropy(pred_reward_probs, target_reward_probs)\n",
    "    loss_s = torch.mean((pred_next_state-new_state)**2)\n",
    "    return dict(\n",
    "        loss_r=loss_r,\n",
    "        loss_s=loss_s,\n",
    "        loss=loss_r+loss_s,\n",
    "    )\n",
    "\n",
    "for step in range(100):\n",
    "    action = np.random.randint(0, 4)\n",
    "    new_state, reward, done, info = env.step(action)\n",
    "    replay_buffer.append((state, action, reward, new_state))\n",
    "    \n",
    "    if done:\n",
    "        state = env.reset()\n",
    "    else:\n",
    "        state = new_state\n",
    "    \n",
    "    if len(replay_buffer) > 2 * batch_size:\n",
    "        idx = np.random.randint(0, len(replay_buffer), batch_size)\n",
    "        batch = [torch.vstack([torch.tensor(replay_buffer[i][j]) for i in idx]) for j in range(4)]\n",
    "        info = train_step(dynamics, batch)\n",
    "        print(info)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4625e10e-2754-455f-be0f-44b5b91006c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
